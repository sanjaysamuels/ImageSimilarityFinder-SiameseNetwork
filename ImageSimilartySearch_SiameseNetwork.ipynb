{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbatqnuTMgvDyFzCobiqqz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjaysamuels/ImageSimilarityFinder-SiameseNetwork/blob/master/ImageSimilartySearch_SiameseNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EAlh34Lhy0D"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Similarity Search\n",
        "\n",
        "To find similar snacks based on the snack image you feed it with, I have employed a Siamese network trained with a triplet loss. This network was trained on a dataset sourced from Huggingface, specifically 'Matthijs/snacks.' The Siamese network is a type of neural network architecture that learns to distinguish between similar and dissimilar items, making it ideal for tasks like image similarity. The triplet loss function encourages the network to reduce the distance between anchor images (the input snack image) and positive images (similar snacks) while increasing the distance between anchor images and negative images (dissimilar snacks). The model achieved a minimum accuracy of 0.8, ensuring it reliably identifies snack similarities. Moreover, the image dataset has been persistently stored in an appropriate storage system for convenient future use.\n",
        "\n"
      ],
      "metadata": {
        "id": "RsCgviGOudkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the \"Matthijs/snacks\" dataset\n",
        "dataset = load_dataset(\"Matthijs/snacks\")"
      ],
      "metadata": {
        "id": "K5cIpQIkh_i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code below allows colab to have access to user drive to save trained image model\n",
        "# Also used to load images to find similar snacks images\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jH0sv0MrkGhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "'''\n",
        "Class SiameseNetwork represents a CNN neural network with two pairs of\n",
        "convolutional layers, followed by ReLU activation functions and max-pooling layers.\n",
        "\n",
        "- During training, the forward method is used to process anchor-positive and\n",
        "anchor-negative pairs in a triplet using the forward_one method.\n",
        "- The anchor and positive inputs go through the network to compute their embeddings,\n",
        "which are then compared to evaluate similarity or dissimilarity.\n",
        "'''\n",
        "class SiameseNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(SiameseNetwork, self).__init__()\n",
        "      self.cnn = nn.Sequential(\n",
        "          nn.Conv2d(3, 64, 5),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(2, 2),\n",
        "          nn.Conv2d(64, 128, 5),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(2, 2)\n",
        "      )\n",
        "      self.fc = nn.Sequential(\n",
        "          nn.AdaptiveAvgPool2d((1, 1)),  # Global Average Pooling (GAP) layer\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(128, 256),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Linear(256, 128)\n",
        "      )\n",
        "\n",
        "  def forward_one(self, x):\n",
        "      x = self.cnn(x)\n",
        "      x = self.fc(x)\n",
        "      return x\n",
        "\n",
        "  def forward(self, input1, input2):\n",
        "      output1 = self.forward_one(input1)\n",
        "      output2 = self.forward_one(input2)\n",
        "      return output1, output2\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "The TripleLoss class is designed for the embeddings (feature vectors) of\n",
        "anchor-positive pairs to be closer in distance while pushing the embeddings of\n",
        "anchor-negative pairs further apart.\n",
        "\n",
        "Reference: https://towardsdatascience.com/siamese-network-triplet-loss-b4ca82c1aec8#:~:text=you%20can%20train%20the%20network,negative%20image%20must%20be%20high.\n",
        "'''\n",
        "class TripletLoss(nn.Module):\n",
        "  def __init__(self, margin=0.9):\n",
        "      super(TripletLoss, self).__init__()\n",
        "      self.margin = margin\n",
        "\n",
        "  def forward(self, anchor, positive, negative):\n",
        "      distance_positive = torch.norm(anchor - positive, p=2, dim=1)\n",
        "      distance_negative = torch.norm(anchor - negative, p=2, dim=1)\n",
        "      loss = torch.clamp(self.margin + distance_positive - distance_negative, min=0.0)\n",
        "      return loss.mean()\n",
        "\n",
        "'''\n",
        "CustomDataset class is used to create a PyTorch-compatible dataset from an input dataset\n",
        "'''\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, dataset, transform=None):\n",
        "      self.dataset = dataset\n",
        "      self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      item = self.dataset[idx]\n",
        "      image = np.array(item[\"image\"])\n",
        "      label = item[\"label\"]\n",
        "      if self.transform:\n",
        "          image = Image.fromarray(image)\n",
        "          image = self.transform(image)\n",
        "      return image, label\n",
        "\n",
        "# Define transformations to resize images to a common size\n",
        "transformImage = transforms.Compose([\n",
        "  transforms.Resize((256, 256)),\n",
        "  transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "custom_dataset = CustomDataset(dataset['train'], transform=transformImage)\n",
        "data_loader = DataLoader(custom_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Initialize the Siamese network and optimizer\n",
        "siamese_net = SiameseNetwork()\n",
        "optimizer = optim.Adam(siamese_net.parameters(), lr=0.0001)\n",
        "\n",
        "# Define the triplet loss function\n",
        "triplet_loss = TripletLoss()\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 7\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "siamese_net.to(device)\n",
        "\n",
        "'''\n",
        "For loop represents the training epochs to train the Siamese Network model.\n",
        "The training is done in bach sizes of 32 which is then split into:\n",
        "Anchor, Positive, and Negative Samples for each batch\n",
        "'''\n",
        "for epoch in range(num_epochs):\n",
        "  total_loss = 0.0\n",
        "  siamese_net.train()\n",
        "  for batch in tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "      batch = [item.to(device) for item in batch]\n",
        "      inputs, labels = batch\n",
        "\n",
        "      # Split the batch into anchor, positive, and negative samples\n",
        "      anchor_indices = torch.randint(0, len(inputs), (inputs.size(0),))\n",
        "      positive_indices = torch.randint(0, len(inputs), (inputs.size(0),))\n",
        "      negative_indices = torch.randint(0, len(inputs), (inputs.size(0),))\n",
        "\n",
        "      anchor_inputs = inputs[anchor_indices]\n",
        "      positive_inputs = inputs[positive_indices]\n",
        "      negative_inputs = inputs[negative_indices]\n",
        "\n",
        "      # Forward pass\n",
        "      anchor_outputs, positive_outputs = siamese_net(anchor_inputs, positive_inputs)\n",
        "      anchor_outputs, negative_outputs = siamese_net(anchor_inputs, negative_inputs)\n",
        "\n",
        "      # Calculate triplet loss\n",
        "      loss = triplet_loss(anchor_outputs, positive_outputs, negative_outputs)\n",
        "\n",
        "      # Backpropagation and optimization\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "  print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(data_loader)}\")\n",
        "\n",
        "# Save the trained Siamese network in your drive\n",
        "# torch.save(siamese_net.state_dict(), \"siamese_net_snacks.pth\")\n",
        "torch.save(siamese_net.state_dict(), '/content/drive/My Drive/Colab Notebooks/siamese_net_snacks.pth')"
      ],
      "metadata": {
        "id": "0D4hE40tiLTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Here load the saved Siamese network that is trained from previous step\n",
        "load_siamese_net = SiameseNetwork()\n",
        "load_siamese_net.load_state_dict(torch.load(\"siamese_net.pth\"))\n",
        "\n",
        "# Define a function to compute embeddings for an image\n",
        "def get_embedding(image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "    with torch.no_grad():\n",
        "        embedding = load_siamese_net.forward_one(image)\n",
        "    return embedding\n",
        "\n",
        "\n",
        "input_image_embedding = get_embedding(\"/content/drive/My Drive/Colab Notebooks/oranges.jpeg\")\n",
        "\n",
        "train_embeddings = []\n",
        "'''\n",
        "For loop below is used to iterate through the training dataset and get image embeddings\n",
        "which will then be used with cosine_similarity to find embeddings that are similar to the input image.\n",
        "'''\n",
        "for idx in range(len(custom_dataset)):\n",
        "    image, _ = custom_dataset[idx]\n",
        "    with torch.no_grad():\n",
        "        embedding = load_siamese_net.forward_one(image.unsqueeze(0).to(device))\n",
        "    train_embeddings.append(embedding)\n",
        "\n",
        "# Calculate similarity scores (cosine similarity)\n",
        "def cosine_similarity(embedding1, embedding2):\n",
        "    similarity = torch.nn.functional.cosine_similarity(embedding1, embedding2)\n",
        "    return similarity.item()"
      ],
      "metadata": {
        "id": "KEOLr-BcNfdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Defining a high similarity threshold to ensure only highly similar images are returned\n",
        "similarity_threshold = 0.9\n",
        "\n",
        "# For loop to find similar images that are in the training dataset\n",
        "similar_images = []\n",
        "for idx, train_embedding in enumerate(train_embeddings):\n",
        "  similarity = cosine_similarity(input_image_embedding, train_embedding)\n",
        "  if similarity >= similarity_threshold:\n",
        "      similar_images.append((idx, similarity))\n",
        "\n",
        "# Sort similar images by similarity score in descending order\n",
        "similar_images.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Display top 5 similar images\n",
        "num_similar_images_to_display = min(5, len(similar_images))\n",
        "for i in range(num_similar_images_to_display):\n",
        "  idx, similarity = similar_images[i]\n",
        "  image, _ = custom_dataset[idx]\n",
        "\n",
        "  # Convert image tensor to numpy array\n",
        "  image_np = image.permute(1, 2, 0).numpy()\n",
        "\n",
        "  # Display the image\n",
        "  plt.figure()\n",
        "  plt.imshow(image_np)\n",
        "  plt.title(f\"Similarity: {similarity:.2f}\")\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "'''\n",
        "Un-comment code below to print the similary score of the similar_images array\n",
        "'''\n",
        "# Print similar images and their similarity scores\n",
        "# for idx, similarity in similar_images:\n",
        "#     image, label = custom_dataset[idx]\n",
        "#     print(f\"Similarity: {similarity:.2f}\")"
      ],
      "metadata": {
        "id": "sWMBKl8aNzE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test dataset to test the trained model's accuracy\n",
        "test_dataset = CustomDataset(dataset['test'], transform=transform)\n",
        "\n",
        "# Compute embeddings for test images\n",
        "test_embeddings = []\n",
        "for idx in range(len(test_dataset)):\n",
        "    image, _ = test_dataset[idx]\n",
        "    with torch.no_grad():\n",
        "        embedding = siamese_net.forward_one(image.unsqueeze(0).to(device))\n",
        "    test_embeddings.append(embedding)\n",
        "\n",
        "validation_similarity_threshold = 0.8\n",
        "\n",
        "# Validation\n",
        "true_positives = 0\n",
        "true_negatives = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "\n",
        "for idx in range(0, len(test_embeddings), 2):\n",
        "  # Get pair of images at idx and idx+1 to represent a positve pair\n",
        "  anchor_embedding = test_embeddings[idx]\n",
        "  positive_embedding = test_embeddings[idx + 1]\n",
        "\n",
        "  # Calculate similarity\n",
        "  similarity = cosine_similarity(anchor_embedding, positive_embedding)\n",
        "\n",
        "  # If condition to determine if the pair is similar or dissimilar\n",
        "  if similarity >= validation_similarity_threshold:\n",
        "      # Similar pair (true positive)\n",
        "      true_positives += 1\n",
        "  else:\n",
        "      # Dissimilar pair (false negative)\n",
        "      false_negatives += 1\n",
        "\n",
        "for idx in range(0, len(test_embeddings), 2):\n",
        "  # Get pair of images at idx and idx+1 to represent a negative pair\n",
        "  anchor_embedding = test_embeddings[idx]\n",
        "  negative_embedding = test_embeddings[idx + 1]\n",
        "\n",
        "  # Calculate similarity\n",
        "  similarity = cosine_similarity(anchor_embedding, negative_embedding)\n",
        "\n",
        "  # If condition to determine if the pair is similar or dissimilar\n",
        "  if similarity < validation_similarity_threshold:\n",
        "      # Dissimilar pair (true negative)\n",
        "      true_negatives += 1\n",
        "  else:\n",
        "      # Similar pair (false positive)\n",
        "      false_positives += 1\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1-score\n",
        "accuracy = (true_positives + true_negatives) / len(test_dataset)\n",
        "precision = true_positives / (true_positives + false_positives)\n",
        "recall = true_positives / (true_positives + false_negatives)\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1_score:.2f}\")\n"
      ],
      "metadata": {
        "id": "3QL99sMkN0Jv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}